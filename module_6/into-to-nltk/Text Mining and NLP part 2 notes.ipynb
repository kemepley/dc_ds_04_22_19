{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining and NLP\n",
    "\n",
    "## Part 2\n",
    "\n",
    "### Situation:\n",
    "\n",
    "Priya works at an international PR firm in the Europe division. Their largest client has offices in Ibiza, Madrid, and Las Palmas. She needs to keep her boss aware of current events and provide a weekly short list of articles concerning political events in Spain. The problem is, this takes hours every week to review articles on the BBC and Priya is very busy! She wonders if she could automate this process using text mining to save her time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Goal**: to internalize the steps, challenges, and methodology of text mining\n",
    "- explore text analysis by hand\n",
    "- apply text mining steps in Jupyter with Python libraries NLTK\n",
    "- classify documents correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresher on cleaning text\n",
    "![gif](https://www.nyfa.edu/student-resources/wp-content/uploads/2014/10/furious-crazed-typing.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "from nltk.collocations import *\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "url_a = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/A.txt\"\n",
    "url_b = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/B.txt\"\n",
    "article_a = urllib.request.urlopen(url_a).read()\n",
    "article_a_st = article_a.decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "arta_tokens_raw = nltk.regexp_tokenize(article_a_st, pattern)\n",
    "\n",
    "# lower case\n",
    "arta_tokens = [i.lower() for i in arta_tokens_raw]\n",
    "\n",
    "# stop words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "arta_tokens_stopped = [w for w in arta_tokens if not w in stop_words]\n",
    "\n",
    "# stem words\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "arta_stemmed = [stemmer.stem(word) for word in arta_tokens_stopped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat w second article\n",
    "article_b = urllib.request.urlopen(url_b).read()\n",
    "article_b_st = article_b.decode(\"utf-8\")\n",
    "artb_tokens_raw = nltk.regexp_tokenize(article_b_st, pattern)\n",
    "artb_tokens = [i.lower() for i in artb_tokens_raw]\n",
    "artb_tokens_stopped = [w for w in artb_tokens if not w in stop_words]\n",
    "artb_stemmed = [stemmer.stem(word) for word in artb_tokens_stopped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what's wrong with the table from yesterday? what does it not consider?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)\n",
    "\n",
    "$\\begin{align}\n",
    " tf_{i,j} = \\dfrac{n_{i,j}}{\\displaystyle \\sum_k n_{i,j} }\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "$\\begin{align}\n",
    "idf(w) = \\log \\dfrac{N}{df_t}\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF score\n",
    "\n",
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing} i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The from scratch method\n",
    "![homemade](https://media2.giphy.com/media/LBZcXdG0eVBdK/giphy.gif?cid=3640f6095c2d7bb2526a424a4d97117c)\n",
    "\n",
    "\n",
    "Please go through the code and comment what each section does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a set of words from both documents (without duplicates)\n",
    "wordSet = set(arta_stemmed).union(set(artb_stemmed))\n",
    "\n",
    "# creating dictionaries with the items in wordSet as the keys and zero as the values\n",
    "wordDictA = dict.fromkeys(wordSet, 0) \n",
    "wordDictB = dict.fromkeys(wordSet, 0) \n",
    "\n",
    "# Adding +1 to each key for each instance of the word in article A\n",
    "for word in arta_stemmed:\n",
    "    wordDictA[word]+=1\n",
    "    \n",
    "# Adding +1 to each key for each instance of the word in article B\n",
    "for word in artb_stemmed:\n",
    "    wordDictB[word]+=1    \n",
    "\n",
    "# creates a dictionary with words as the keys and the number of times the word appears in the doc divided by the \n",
    "# total number of words in the document\n",
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict\n",
    "\n",
    "tfbowA = computeTF(wordDictA,arta_stemmed)\n",
    "tfbowB = computeTF(wordDictB,artb_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chanc': 0.005434782608695652,\n",
       " 'innov': 0.005434782608695652,\n",
       " 'deal': 0.0,\n",
       " 'hold': 0.005434782608695652,\n",
       " 'agreement': 0.0,\n",
       " 'exampl': 0.005434782608695652,\n",
       " 'draft': 0.016304347826086956,\n",
       " 'law': 0.02717391304347826,\n",
       " 'invent': 0.02717391304347826,\n",
       " 'small': 0.010869565217391304,\n",
       " 'controversi': 0.005434782608695652,\n",
       " 'patent': 0.02717391304347826,\n",
       " 'rewrit': 0.005434782608695652,\n",
       " 'hurt': 0.005434782608695652,\n",
       " 'use': 0.005434782608695652,\n",
       " 'shop': 0.005434782608695652,\n",
       " 'hit': 0.0,\n",
       " 'ineffici': 0.005434782608695652,\n",
       " 'us': 0.016304347826086956,\n",
       " 'fail': 0.005434782608695652,\n",
       " 'fund': 0.0,\n",
       " 'legal': 0.016304347826086956,\n",
       " 'lobbi': 0.005434782608695652,\n",
       " 'suspend': 0.0,\n",
       " 'hope': 0.0,\n",
       " 'two': 0.010869565217391304,\n",
       " 'serv': 0.005434782608695652,\n",
       " 'secretari': 0.0,\n",
       " 'canada': 0.0,\n",
       " 'even': 0.005434782608695652,\n",
       " 'begun': 0.0,\n",
       " 'amazon': 0.005434782608695652,\n",
       " 'bring': 0.005434782608695652,\n",
       " 'hammer': 0.0,\n",
       " 'europ': 0.005434782608695652,\n",
       " 'support': 0.010869565217391304,\n",
       " 'commiss': 0.005434782608695652,\n",
       " 'word': 0.005434782608695652,\n",
       " 'foreign': 0.0,\n",
       " 'method': 0.005434782608695652,\n",
       " 'reject': 0.005434782608695652,\n",
       " 'debat': 0.005434782608695652,\n",
       " 'fight': 0.005434782608695652,\n",
       " 'model': 0.005434782608695652,\n",
       " 'freez': 0.0,\n",
       " 'could': 0.016304347826086956,\n",
       " 'mr': 0.0,\n",
       " 'would': 0.016304347826086956,\n",
       " 'financ': 0.0,\n",
       " 'implement': 0.010869565217391304,\n",
       " 'give': 0.005434782608695652,\n",
       " 'world': 0.0,\n",
       " 'order': 0.010869565217391304,\n",
       " 'wealthi': 0.0,\n",
       " 'problem': 0.0,\n",
       " 'year': 0.0,\n",
       " 'committe': 0.010869565217391304,\n",
       " 'pound': 0.0,\n",
       " 'repay': 0.0,\n",
       " 'brown': 0.0,\n",
       " 'say': 0.016304347826086956,\n",
       " 'field': 0.005434782608695652,\n",
       " 'union': 0.005434782608695652,\n",
       " 'straw': 0.0,\n",
       " 'chair': 0.0,\n",
       " 'number': 0.0,\n",
       " 'come': 0.0,\n",
       " 'affair': 0.005434782608695652,\n",
       " 'mep': 0.010869565217391304,\n",
       " 'one': 0.016304347826086956,\n",
       " 'interest': 0.0,\n",
       " 'talk': 0.0,\n",
       " 'financi': 0.005434782608695652,\n",
       " 'govern': 0.005434782608695652,\n",
       " 'mean': 0.005434782608695652,\n",
       " 'jack': 0.0,\n",
       " 'minist': 0.0,\n",
       " 'countri': 0.0,\n",
       " 'without': 0.005434782608695652,\n",
       " 'decis': 0.005434782608695652,\n",
       " 'debt': 0.0,\n",
       " 'impact': 0.005434782608695652,\n",
       " 'back': 0.010869565217391304,\n",
       " 'monetari': 0.0,\n",
       " 'permit': 0.005434782608695652,\n",
       " 'lock': 0.0,\n",
       " 'idea': 0.0,\n",
       " 'com': 0.005434782608695652,\n",
       " 'eu': 0.021739130434782608,\n",
       " 'program': 0.005434782608695652,\n",
       " 'twice': 0.005434782608695652,\n",
       " 'implic': 0.005434782608695652,\n",
       " 'later': 0.0,\n",
       " 'start': 0.005434782608695652,\n",
       " 'critic': 0.010869565217391304,\n",
       " 'new': 0.010869565217391304,\n",
       " 'softwar': 0.016304347826086956,\n",
       " 'miss': 0.0,\n",
       " 'suffer': 0.005434782608695652,\n",
       " 'believ': 0.0,\n",
       " 'g': 0.0,\n",
       " 'vote': 0.005434782608695652,\n",
       " 'action': 0.005434782608695652,\n",
       " 'save': 0.0,\n",
       " 'concern': 0.005434782608695652,\n",
       " 'creditor': 0.0,\n",
       " 'momentum': 0.005434782608695652,\n",
       " 'submit': 0.005434782608695652,\n",
       " 'protect': 0.010869565217391304,\n",
       " 'vocal': 0.005434782608695652,\n",
       " 'japan': 0.0,\n",
       " 'face': 0.0,\n",
       " 'friday': 0.0,\n",
       " 'member': 0.010869565217391304,\n",
       " 'larger': 0.005434782608695652,\n",
       " 'pressur': 0.005434782608695652,\n",
       " 'propos': 0.010869565217391304,\n",
       " 'setback': 0.005434782608695652,\n",
       " 'fear': 0.005434782608695652,\n",
       " 'put': 0.005434782608695652,\n",
       " 'develop': 0.005434782608695652,\n",
       " 'abstain': 0.005434782608695652,\n",
       " 'direct': 0.021739130434782608,\n",
       " 'affect': 0.0,\n",
       " 'gain': 0.005434782608695652,\n",
       " 'reach': 0.0,\n",
       " 'night': 0.0,\n",
       " 'meet': 0.005434782608695652,\n",
       " 'week': 0.0,\n",
       " 'tsunami': 0.0,\n",
       " 'dead': 0.0,\n",
       " 'servic': 0.005434782608695652,\n",
       " 'germani': 0.0,\n",
       " 'sourc': 0.005434782608695652,\n",
       " 'analysi': 0.0,\n",
       " 'intend': 0.005434782608695652,\n",
       " 'might': 0.005434782608695652,\n",
       " 'reboot': 0.005434782608695652,\n",
       " 'achiev': 0.005434782608695652,\n",
       " 'expect': 0.0,\n",
       " 'european': 0.010869565217391304,\n",
       " 'immens': 0.005434782608695652,\n",
       " 'internet': 0.005434782608695652,\n",
       " 'bn': 0.0,\n",
       " 'also': 0.0,\n",
       " 'announc': 0.0,\n",
       " 'compani': 0.005434782608695652,\n",
       " 'read': 0.005434782608695652,\n",
       " 'comput': 0.021739130434782608,\n",
       " 'open': 0.005434782608695652,\n",
       " 'said': 0.010869565217391304,\n",
       " 'adopt': 0.005434782608695652,\n",
       " 'play': 0.005434782608695652,\n",
       " 'group': 0.0,\n",
       " 'juri': 0.010869565217391304,\n",
       " 'effect': 0.005434782608695652,\n",
       " 'nation': 0.005434782608695652,\n",
       " 'agre': 0.0,\n",
       " 'bank': 0.0,\n",
       " 'parliament': 0.010869565217391304,\n",
       " 'gordon': 0.0,\n",
       " 'instruct': 0.0,\n",
       " 'court': 0.005434782608695652,\n",
       " 'thursday': 0.0,\n",
       " 'lead': 0.005434782608695652,\n",
       " 'fuller': 0.005434782608695652,\n",
       " 'britain': 0.0,\n",
       " 'firm': 0.010869565217391304,\n",
       " 'chancellor': 0.0,\n",
       " 'line': 0.005434782608695652,\n",
       " 'complet': 0.0,\n",
       " 'sign': 0.0,\n",
       " 'final': 0.0,\n",
       " 'moratorium': 0.0,\n",
       " 'earlier': 0.0,\n",
       " 'offer': 0.005434782608695652,\n",
       " 'first': 0.005434782608695652,\n",
       " 'reconstruct': 0.0,\n",
       " 'welcom': 0.005434782608695652,\n",
       " 'month': 0.005434782608695652,\n",
       " 'biggest': 0.0,\n",
       " 'rule': 0.005434782608695652,\n",
       " 'larg': 0.005434782608695652,\n",
       " 'click': 0.005434782608695652,\n",
       " 'disast': 0.0,\n",
       " 'poland': 0.005434782608695652,\n",
       " 'intens': 0.005434782608695652,\n",
       " 'state': 0.010869565217391304,\n",
       " 'thought': 0.0,\n",
       " 'let': 0.005434782608695652,\n",
       " 'issu': 0.005434782608695652,\n",
       " 'oppon': 0.005434782608695652,\n",
       " 'base': 0.010869565217391304,\n",
       " 'briton': 0.0,\n",
       " 'happen': 0.005434782608695652,\n",
       " 'favour': 0.005434782608695652,\n",
       " 'largest': 0.005434782608695652,\n",
       " 'current': 0.005434782608695652,\n",
       " 'busi': 0.005434782608695652,\n",
       " 'intern': 0.0,\n",
       " 'similar': 0.005434782608695652}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "# creating a dictionary with the keys from the first dictionary in the docList (since they have the same keys) \n",
    "# and zero values\n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "# for each dictionary's values, find out if it's greater than zero. If it is, then add one that value's key in \n",
    "# the idfDict dictionary \n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "# Compute the TF-IDF for each word/value pair: take the natural log of the number of documents in the doclist \n",
    "# divided by value)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chanc': 0.3010299956639812,\n",
       " 'innov': 0.3010299956639812,\n",
       " 'deal': 0.3010299956639812,\n",
       " 'hold': 0.3010299956639812,\n",
       " 'agreement': 0.3010299956639812,\n",
       " 'exampl': 0.3010299956639812,\n",
       " 'draft': 0.3010299956639812,\n",
       " 'law': 0.3010299956639812,\n",
       " 'invent': 0.3010299956639812,\n",
       " 'small': 0.3010299956639812,\n",
       " 'controversi': 0.3010299956639812,\n",
       " 'patent': 0.3010299956639812,\n",
       " 'rewrit': 0.3010299956639812,\n",
       " 'hurt': 0.3010299956639812,\n",
       " 'use': 0.3010299956639812,\n",
       " 'shop': 0.3010299956639812,\n",
       " 'hit': 0.3010299956639812,\n",
       " 'ineffici': 0.3010299956639812,\n",
       " 'us': 0.3010299956639812,\n",
       " 'fail': 0.3010299956639812,\n",
       " 'fund': 0.3010299956639812,\n",
       " 'legal': 0.3010299956639812,\n",
       " 'lobbi': 0.3010299956639812,\n",
       " 'suspend': 0.3010299956639812,\n",
       " 'hope': 0.3010299956639812,\n",
       " 'two': 0.3010299956639812,\n",
       " 'serv': 0.3010299956639812,\n",
       " 'secretari': 0.3010299956639812,\n",
       " 'canada': 0.3010299956639812,\n",
       " 'even': 0.3010299956639812,\n",
       " 'begun': 0.3010299956639812,\n",
       " 'amazon': 0.3010299956639812,\n",
       " 'bring': 0.3010299956639812,\n",
       " 'hammer': 0.3010299956639812,\n",
       " 'europ': 0.3010299956639812,\n",
       " 'support': 0.3010299956639812,\n",
       " 'commiss': 0.3010299956639812,\n",
       " 'word': 0.3010299956639812,\n",
       " 'foreign': 0.3010299956639812,\n",
       " 'method': 0.3010299956639812,\n",
       " 'reject': 0.3010299956639812,\n",
       " 'debat': 0.3010299956639812,\n",
       " 'fight': 0.3010299956639812,\n",
       " 'model': 0.3010299956639812,\n",
       " 'freez': 0.3010299956639812,\n",
       " 'could': 0.3010299956639812,\n",
       " 'mr': 0.3010299956639812,\n",
       " 'would': 0.0,\n",
       " 'financ': 0.3010299956639812,\n",
       " 'implement': 0.3010299956639812,\n",
       " 'give': 0.3010299956639812,\n",
       " 'world': 0.3010299956639812,\n",
       " 'order': 0.3010299956639812,\n",
       " 'wealthi': 0.3010299956639812,\n",
       " 'problem': 0.3010299956639812,\n",
       " 'year': 0.3010299956639812,\n",
       " 'committe': 0.3010299956639812,\n",
       " 'pound': 0.3010299956639812,\n",
       " 'repay': 0.3010299956639812,\n",
       " 'brown': 0.3010299956639812,\n",
       " 'say': 0.3010299956639812,\n",
       " 'field': 0.3010299956639812,\n",
       " 'union': 0.3010299956639812,\n",
       " 'straw': 0.3010299956639812,\n",
       " 'chair': 0.3010299956639812,\n",
       " 'number': 0.3010299956639812,\n",
       " 'come': 0.3010299956639812,\n",
       " 'affair': 0.3010299956639812,\n",
       " 'mep': 0.3010299956639812,\n",
       " 'one': 0.0,\n",
       " 'interest': 0.3010299956639812,\n",
       " 'talk': 0.3010299956639812,\n",
       " 'financi': 0.3010299956639812,\n",
       " 'govern': 0.3010299956639812,\n",
       " 'mean': 0.3010299956639812,\n",
       " 'jack': 0.3010299956639812,\n",
       " 'minist': 0.3010299956639812,\n",
       " 'countri': 0.3010299956639812,\n",
       " 'without': 0.3010299956639812,\n",
       " 'decis': 0.3010299956639812,\n",
       " 'debt': 0.3010299956639812,\n",
       " 'impact': 0.3010299956639812,\n",
       " 'back': 0.3010299956639812,\n",
       " 'monetari': 0.3010299956639812,\n",
       " 'permit': 0.3010299956639812,\n",
       " 'lock': 0.3010299956639812,\n",
       " 'idea': 0.3010299956639812,\n",
       " 'com': 0.3010299956639812,\n",
       " 'eu': 0.3010299956639812,\n",
       " 'program': 0.3010299956639812,\n",
       " 'twice': 0.3010299956639812,\n",
       " 'implic': 0.3010299956639812,\n",
       " 'later': 0.3010299956639812,\n",
       " 'start': 0.3010299956639812,\n",
       " 'critic': 0.3010299956639812,\n",
       " 'new': 0.3010299956639812,\n",
       " 'softwar': 0.3010299956639812,\n",
       " 'miss': 0.3010299956639812,\n",
       " 'suffer': 0.3010299956639812,\n",
       " 'believ': 0.3010299956639812,\n",
       " 'g': 0.3010299956639812,\n",
       " 'vote': 0.3010299956639812,\n",
       " 'action': 0.3010299956639812,\n",
       " 'save': 0.3010299956639812,\n",
       " 'concern': 0.3010299956639812,\n",
       " 'creditor': 0.3010299956639812,\n",
       " 'momentum': 0.3010299956639812,\n",
       " 'submit': 0.3010299956639812,\n",
       " 'protect': 0.3010299956639812,\n",
       " 'vocal': 0.3010299956639812,\n",
       " 'japan': 0.3010299956639812,\n",
       " 'face': 0.3010299956639812,\n",
       " 'friday': 0.3010299956639812,\n",
       " 'member': 0.3010299956639812,\n",
       " 'larger': 0.3010299956639812,\n",
       " 'pressur': 0.3010299956639812,\n",
       " 'propos': 0.0,\n",
       " 'setback': 0.3010299956639812,\n",
       " 'fear': 0.3010299956639812,\n",
       " 'put': 0.3010299956639812,\n",
       " 'develop': 0.3010299956639812,\n",
       " 'abstain': 0.3010299956639812,\n",
       " 'direct': 0.3010299956639812,\n",
       " 'affect': 0.3010299956639812,\n",
       " 'gain': 0.3010299956639812,\n",
       " 'reach': 0.3010299956639812,\n",
       " 'night': 0.3010299956639812,\n",
       " 'meet': 0.3010299956639812,\n",
       " 'week': 0.3010299956639812,\n",
       " 'tsunami': 0.3010299956639812,\n",
       " 'dead': 0.3010299956639812,\n",
       " 'servic': 0.3010299956639812,\n",
       " 'germani': 0.3010299956639812,\n",
       " 'sourc': 0.3010299956639812,\n",
       " 'analysi': 0.3010299956639812,\n",
       " 'intend': 0.3010299956639812,\n",
       " 'might': 0.3010299956639812,\n",
       " 'reboot': 0.3010299956639812,\n",
       " 'achiev': 0.3010299956639812,\n",
       " 'expect': 0.3010299956639812,\n",
       " 'european': 0.3010299956639812,\n",
       " 'immens': 0.3010299956639812,\n",
       " 'internet': 0.3010299956639812,\n",
       " 'bn': 0.3010299956639812,\n",
       " 'also': 0.3010299956639812,\n",
       " 'announc': 0.3010299956639812,\n",
       " 'compani': 0.3010299956639812,\n",
       " 'read': 0.3010299956639812,\n",
       " 'comput': 0.3010299956639812,\n",
       " 'open': 0.3010299956639812,\n",
       " 'said': 0.0,\n",
       " 'adopt': 0.3010299956639812,\n",
       " 'play': 0.3010299956639812,\n",
       " 'group': 0.3010299956639812,\n",
       " 'juri': 0.3010299956639812,\n",
       " 'effect': 0.3010299956639812,\n",
       " 'nation': 0.0,\n",
       " 'agre': 0.3010299956639812,\n",
       " 'bank': 0.3010299956639812,\n",
       " 'parliament': 0.3010299956639812,\n",
       " 'gordon': 0.3010299956639812,\n",
       " 'instruct': 0.3010299956639812,\n",
       " 'court': 0.3010299956639812,\n",
       " 'thursday': 0.3010299956639812,\n",
       " 'lead': 0.3010299956639812,\n",
       " 'fuller': 0.3010299956639812,\n",
       " 'britain': 0.3010299956639812,\n",
       " 'firm': 0.3010299956639812,\n",
       " 'chancellor': 0.3010299956639812,\n",
       " 'line': 0.3010299956639812,\n",
       " 'complet': 0.3010299956639812,\n",
       " 'sign': 0.3010299956639812,\n",
       " 'final': 0.3010299956639812,\n",
       " 'moratorium': 0.3010299956639812,\n",
       " 'earlier': 0.3010299956639812,\n",
       " 'offer': 0.3010299956639812,\n",
       " 'first': 0.0,\n",
       " 'reconstruct': 0.3010299956639812,\n",
       " 'welcom': 0.3010299956639812,\n",
       " 'month': 0.3010299956639812,\n",
       " 'biggest': 0.3010299956639812,\n",
       " 'rule': 0.3010299956639812,\n",
       " 'larg': 0.3010299956639812,\n",
       " 'click': 0.3010299956639812,\n",
       " 'disast': 0.3010299956639812,\n",
       " 'poland': 0.3010299956639812,\n",
       " 'intens': 0.3010299956639812,\n",
       " 'state': 0.0,\n",
       " 'thought': 0.3010299956639812,\n",
       " 'let': 0.3010299956639812,\n",
       " 'issu': 0.3010299956639812,\n",
       " 'oppon': 0.3010299956639812,\n",
       " 'base': 0.3010299956639812,\n",
       " 'briton': 0.3010299956639812,\n",
       " 'happen': 0.3010299956639812,\n",
       " 'favour': 0.3010299956639812,\n",
       " 'largest': 0.3010299956639812,\n",
       " 'current': 0.3010299956639812,\n",
       " 'busi': 0.3010299956639812,\n",
       " 'intern': 0.3010299956639812,\n",
       " 'similar': 0.3010299956639812}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "\n",
    "# for each item in the tf dic, calculating the value times the corresponding value in the idfs dictionary \n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA = computeTFIDF(tfbowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfbowB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>affect</th>\n",
       "      <th>agre</th>\n",
       "      <th>agreement</th>\n",
       "      <th>also</th>\n",
       "      <th>amazon</th>\n",
       "      <th>...</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>wealthi</th>\n",
       "      <th>week</th>\n",
       "      <th>welcom</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstain    achiev    action     adopt    affair    affect      agre  \\\n",
       "0  0.001636  0.001636  0.001636  0.001636  0.001636  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.002923  0.002923   \n",
       "\n",
       "   agreement      also    amazon  ...     vocal      vote   wealthi      week  \\\n",
       "0   0.000000  0.000000  0.001636  ...  0.001636  0.001636  0.000000  0.000000   \n",
       "1   0.002923  0.005845  0.000000  ...  0.000000  0.000000  0.002923  0.002923   \n",
       "\n",
       "     welcom   without      word     world  would      year  \n",
       "0  0.001636  0.001636  0.001636  0.000000    0.0  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.002923    0.0  0.002923  \n",
       "\n",
       "[2 rows x 201 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([tfidfBowA, tfidfBowB])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But yes, there is an easier way\n",
    "\n",
    "![big deal](https://media0.giphy.com/media/xUA7aQOxkz00lvCAOQ/giphy.gif?cid=3640f6095c2d7c51772f47644d09cc8b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    abstain    achiev    action     adopt    affair    affect      agre  \\\n",
      "0  0.053285  0.053285  0.053285  0.053285  0.053285  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.084167  0.084167   \n",
      "\n",
      "   agreement      also    amazon  ...     vocal      vote   wealthi      week  \\\n",
      "0   0.000000  0.000000  0.053285  ...  0.053285  0.053285  0.000000  0.000000   \n",
      "1   0.084167  0.168334  0.000000  ...  0.000000  0.000000  0.084167  0.084167   \n",
      "\n",
      "     welcom   without      word     world     would      year  \n",
      "0  0.053285  0.053285  0.053285  0.000000  0.113738  0.000000  \n",
      "1  0.000000  0.000000  0.000000  0.084167  0.059885  0.084167  \n",
      "\n",
      "[2 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a string again\n",
    "cleaned_a = ' '.join(arta_stemmed)\n",
    "cleaned_b = ' '.join(artb_stemmed)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform([cleaned_a, cleaned_b])\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Statistics \n",
    "\n",
    "How many non-zero elements are there?\n",
    "- Adapt the code below, using the `df` version of the `response` object to replace everywhere below it says `DATA`\n",
    "- Interpret the findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 103.5\n",
      "Percentage of columns containing 0: 0.48250000000000004\n"
     ]
    }
   ],
   "source": [
    "# Edit code before running it\n",
    "\n",
    "newval=np.array(df)\n",
    "\n",
    "non_zero_vals = np.count_nonzero(newval) / float(df.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_vals))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / float(df.shape[1]))\n",
    "print('Percentage of columns containing 0: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "- Create the tf-idf for the **whole** corpus of 12 articles\n",
    "- What are _on average_ the most important words in the whole corpus?\n",
    "- Add a column named \"Target\" to the dataset\n",
    "- Target will be set to 1 or 0 if the article is \"Politics\" or \"Not Politics\"\n",
    "- Do some exploratory analysis of the dataset\n",
    " - what are the average most important words for the \"Politics\" articles?\n",
    " - What are the average most important words for the \"Not Politics\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets talk classification\n",
    "- How would you split into train and test? what would be the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
